{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spell Checker.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNQOynOPlpqwuc59qh8gtX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyaabdul/N-Gram-and-Spell-Checker/blob/master/Spell_Checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWFpEbGbMUTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open('/content/text_tere_liye_fb08042020.txt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6vX3P52ghN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "aef2de47-00f0-41f0-f809-66eb3f957156"
      },
      "source": [
        "!pip install sastrawi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sastrawi\n",
            "Successfully installed sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjtdsIx3MYqk",
        "colab_type": "code",
        "outputId": "8f481583-3ad4-4fdb-f02a-a93f4a52ae78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import re\n",
        "from nltk.util import ngrams\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "\n",
        "#ubah menjadi lower text\n",
        "text = text.lower()\n",
        "#hilangkan karakter selain huruf dan angka\n",
        "text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
        "#hilagkan \\n pada kalimat\n",
        "text = re.sub(r'\\n','',text)\n",
        "\n",
        "#buat stopword\n",
        "factory = StopWordRemoverFactory()\n",
        "stopword = factory.create_stop_word_remover()\n",
        "\n",
        "#hilangkan stopword pada kalimat\n",
        "stop = stopword.remove(text)\n",
        "\n",
        "#buat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "#stemming kata\n",
        "stem = stemmer.stem(stop)\n",
        "\n",
        "#split kalimat menjadi token per kata\n",
        "tokens = [token for token in stem.split(\" \") if token != \"\"]\n",
        "\n",
        "#n-gram 1 token/kata\n",
        "token1 = list(ngrams(tokens,1))\n",
        "#n-gram 2 token/kata\n",
        "token2 = list(ngrams(tokens,2))\n",
        "#n-gram 3 token/kata\n",
        "token3 = list(ngrams(tokens,3))\n",
        "\n",
        "\n",
        "print(token1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('buat',), ('kalian',), ('tiap',), ('hari',), ('kritik',), ('perintah',), ('sudah',), ('kalian',), ('isi',), ('setor',), ('spt',), ('2019',), ('buat',), ('kalian',), ('tiap',), ('hari',), ('puja',), ('muji',), ('perintah',), ('lantas',), ('ngamuk',), ('baca',), ('tulis',), ('kritik',), ('perintah',), ('sudah',), ('kalian',), ('isi',), ('setor',), ('spt',), ('2019',), ('salah',), ('satu',), ('wajib',), ('warga',), ('negara',), ('bayar',), ('pajak',), ('benci',), ('minta',), ('ampun',), ('lihat',), ('fakta',), ('juta',), ('buku2',), ('baja',), ('jual',), ('shopee',), ('tokopedia',), ('bukalapak',), ('lazada',), ('mau',), ('marah',), ('ubun2',), ('lihat',), ('juta',), ('orang',), ('tonton',), ('film2',), ('buku',), ('sy',), ('ilegal',), ('lagi',), ('juta',), ('ebook',), ('ilegal',), ('bagi',), ('whatsapp',), ('sy',), ('bahkan',), ('lapor',), ('menteri',), ('periode',), ('lalu',), ('soal',), ('minta',), ('karya',), ('sy',), ('lindung',), ('tetap',), ('hak',), ('sy',), ('wni',), ('tdk',), ('lindung',), ('marah',), ('sy',), ('tetap',), ('bayar',), ('pajak',), ('tetap',), ('lapor',), ('setor',), ('spt',), ('2019',), ('sakit',), ('hati',), ('sy',), ('tetap',), ('bayar',), ('pajak',), ('paham',), ('cinta',), ('negara',), ('itu',), ('tidak',), ('lihat',), ('berapa',), ('banyak',), ('postingan',), ('kalian',), ('media',), ('sosial',), ('lihat',), ('berapa',), ('banyak',), ('kontribusi',), ('kalian',), ('negara',), ('itu',), ('salah',), ('satu',), ('adalah',), ('pajak',), ('jadi',), ('ayo',), ('deadline',), ('tambah',), ('nya',), ('habis',), ('lapor',), ('spt',), ('2019',), ('kalian',), ('henti',), ('dulu',), ('berisik',), ('jadi',), ('buzzer',), ('medsos',), ('puja',), ('puji',), ('hampar',), ('juga',), ('balik',), ('henti',), ('dulu',), ('nulis',), ('kritik',), ('kalau',), ('lapor',), ('spt',), ('2019',), ('monggo',), ('lanjut',), ('jadi',), ('buzzer',), ('kritikus',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iLbg3vh0PKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab20263b-ea69-4a64-af2b-25e993e02d16"
      },
      "source": [
        "cekkata=[]\n",
        "x=0\n",
        "\n",
        "for cek in token1:\n",
        "  # cek = re.sub(r'\\W','',cek)\n",
        "  cekkata.append(cek)\n",
        "\n",
        "# x=0\n",
        "# for c in cekkata:\n",
        "#   cekkata[x] = re.sub(r'\\W','',cekkata[x])\n",
        "#   print(cekkata[x])\n",
        "  x=x+1\n",
        "  \n",
        "\n",
        "\n",
        "print(cekkata)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('buat',), ('kalian',), ('tiap',), ('hari',), ('kritik',), ('perintah',), ('sudah',), ('kalian',), ('isi',), ('setor',), ('spt',), ('2019',), ('buat',), ('kalian',), ('tiap',), ('hari',), ('puja',), ('muji',), ('perintah',), ('lantas',), ('ngamuk',), ('baca',), ('tulis',), ('kritik',), ('perintah',), ('sudah',), ('kalian',), ('isi',), ('setor',), ('spt',), ('2019',), ('salah',), ('satu',), ('wajib',), ('warga',), ('negara',), ('bayar',), ('pajak',), ('benci',), ('minta',), ('ampun',), ('lihat',), ('fakta',), ('juta',), ('buku2',), ('baja',), ('jual',), ('shopee',), ('tokopedia',), ('bukalapak',), ('lazada',), ('mau',), ('marah',), ('ubun2',), ('lihat',), ('juta',), ('orang',), ('tonton',), ('film2',), ('buku',), ('sy',), ('ilegal',), ('lagi',), ('juta',), ('ebook',), ('ilegal',), ('bagi',), ('whatsapp',), ('sy',), ('bahkan',), ('lapor',), ('menteri',), ('periode',), ('lalu',), ('soal',), ('minta',), ('karya',), ('sy',), ('lindung',), ('tetap',), ('hak',), ('sy',), ('wni',), ('tdk',), ('lindung',), ('marah',), ('sy',), ('tetap',), ('bayar',), ('pajak',), ('tetap',), ('lapor',), ('setor',), ('spt',), ('2019',), ('sakit',), ('hati',), ('sy',), ('tetap',), ('bayar',), ('pajak',), ('paham',), ('cinta',), ('negara',), ('itu',), ('tidak',), ('lihat',), ('berapa',), ('banyak',), ('postingan',), ('kalian',), ('media',), ('sosial',), ('lihat',), ('berapa',), ('banyak',), ('kontribusi',), ('kalian',), ('negara',), ('itu',), ('salah',), ('satu',), ('adalah',), ('pajak',), ('jadi',), ('ayo',), ('deadline',), ('tambah',), ('nya',), ('habis',), ('lapor',), ('spt',), ('2019',), ('kalian',), ('henti',), ('dulu',), ('berisik',), ('jadi',), ('buzzer',), ('medsos',), ('puja',), ('puji',), ('hampar',), ('juga',), ('balik',), ('henti',), ('dulu',), ('nulis',), ('kritik',), ('kalau',), ('lapor',), ('spt',), ('2019',), ('monggo',), ('lanjut',), ('jadi',), ('buzzer',), ('kritikus',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf0oo4yeCDb5",
        "colab_type": "code",
        "outputId": "d4595407-2f4f-4951-c707-3dfa6bfa06fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "WORDS = Counter(words(open('/content/kata_dasar.txt').read()))\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    # \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "def correction(word):\n",
        "    # \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "\n",
        "def candidates(word):\n",
        "    # \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "def known(words):\n",
        "    # \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "def edits1(word):\n",
        "    # \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)] # [('', 'kemarin'), ('k', 'emarin'), ('ke', 'marin'), dst]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R] # ['emarin', 'kmarin', 'kearin', dst]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1] # ['ekmarin', 'kmearin', 'keamrin', dst]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters] # ['aemarin', 'bemarin', 'cemarin', dst]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters] # ['akemarin', 'bkemarin', 'ckemarin', dst]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "def edits2(word):\n",
        "    # \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "\n",
        "\n",
        "cekkata=[]\n",
        "x=0\n",
        "\n",
        "for cek in token1:\n",
        "  cekkata.append(cek)\n",
        "  x=x+1\n",
        "\n",
        "\n",
        "for cek in cekkata:\n",
        "  kata = str(cekkata[x])\n",
        "  kata = re.sub(r'\\W','',kata) \n",
        "  \n",
        "  if correction(kata) != kata:\n",
        "    print('kata typo : ', kata)\n",
        "    print('koreksi : ', correction(kata))\n",
        "  x=x+1\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7160632cfea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcek\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcekkata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mkata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcekkata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0mkata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\W'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}